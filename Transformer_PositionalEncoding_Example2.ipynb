{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f4da4a8",
   "metadata": {},
   "source": [
    "# Lecture 5 Transformer - Positional Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff4a486",
   "metadata": {},
   "source": [
    "#### Positional Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e101089d",
   "metadata": {},
   "source": [
    "Positional encoding is a technique used to add positional information to input embeddings in Transformer models, allowing the model to understand the order of tokens in a sequence (since Transformers are order-agnostic by default). Below are three Python coding examples that progressively illustrate how positional encoding works:\n",
    "- Basic Positional Encoding (Sine & Cosine) from Scratch\n",
    "- Positional Encoding in a Simple Transformer Model\n",
    "- Learnable Positional Encoding Using PyTorch (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71695e3a",
   "metadata": {},
   "source": [
    "#### 3. Learnable Positional Encoding Using PyTorch\n",
    "In this example, we implement learnable positional encoding, where the positional information is learned during training rather than being predefined using sine and cosine functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31db16c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learnable Positional Encoding:\n",
      " Parameter containing:\n",
      "tensor([[[-0.1276, -0.6889,  0.8759, -0.0136,  0.7803,  1.0841,  0.1368,\n",
      "          -1.1224,  0.5634,  1.3568, -0.4604,  0.0918,  0.1806,  1.8718,\n",
      "          -0.9727,  0.5435],\n",
      "         [ 1.4102,  0.8206, -0.8326, -0.3513,  2.6679,  1.2296,  0.5776,\n",
      "           0.9855, -0.7315,  0.7948,  0.0057,  0.4612,  0.1047, -0.3921,\n",
      "          -2.6505, -0.1576],\n",
      "         [ 1.5602,  0.7220,  0.4299, -0.2796, -0.8408,  2.1729,  1.6441,\n",
      "           0.4115,  0.8372, -0.7143, -1.4775,  1.6577,  0.6052,  1.5958,\n",
      "           0.0325,  0.1703],\n",
      "         [-0.2209, -0.2384,  0.6595,  0.3653, -1.7404,  0.9811,  0.3686,\n",
      "           1.2329,  1.9262, -0.0741,  0.7718, -0.0156, -1.1351, -0.4721,\n",
      "          -0.5552,  0.7829],\n",
      "         [-0.5426, -0.9944, -1.2903, -0.5876,  1.7312,  0.4334, -0.5261,\n",
      "           0.9414, -0.0810, -0.9085,  0.1460, -0.0696, -1.2196,  0.5070,\n",
      "           0.9800, -1.0328],\n",
      "         [ 0.2745, -0.6019, -1.6439,  1.7115, -0.9995, -0.3480,  0.9282,\n",
      "          -0.8452, -0.0325, -0.9845,  1.1140, -0.9144, -0.9187, -0.7696,\n",
      "          -0.5658,  1.2364],\n",
      "         [ 0.7892, -0.4896,  0.7706, -0.0635, -0.0946,  0.9281,  0.3344,\n",
      "          -0.2765,  0.9054, -0.1491,  0.3721, -2.5960,  1.3602,  1.6370,\n",
      "           0.6647,  0.5105],\n",
      "         [ 0.8064,  0.2125,  0.1376,  1.0113, -1.6999,  0.1753, -0.1485,\n",
      "          -0.3783,  0.1966, -1.9993, -0.9501,  0.5624, -1.4211,  0.0151,\n",
      "           1.1937,  0.7229],\n",
      "         [-1.0182, -0.7830,  1.5156,  0.0609,  1.0781, -0.4140, -0.0278,\n",
      "          -0.8139,  0.2791,  0.6253, -0.0753,  0.7122,  0.4336, -1.1766,\n",
      "          -0.6834,  0.9457],\n",
      "         [ 0.6269,  1.1565,  1.0639, -2.6422, -0.5464,  0.4239, -0.0153,\n",
      "           0.0705,  0.5218,  0.7007, -1.7628, -1.6190, -0.7377, -0.4221,\n",
      "           0.8800, -1.1360]]], requires_grad=True)\n",
      "Input + Positional Encoding:\n",
      " tensor([[[-1.7323, -1.0546,  1.6223,  0.0670,  0.4373,  0.8810, -0.2793,\n",
      "          -0.3419,  1.4069,  1.0645, -0.8958,  0.8861,  0.8941,  1.5799,\n",
      "          -0.1074,  2.1643],\n",
      "         [ 0.1529,  0.8134, -1.0271, -2.3308,  3.1196,  1.8837, -1.3298,\n",
      "          -1.4650, -0.1584,  0.8106, -1.0070,  2.2227,  0.8082, -1.1106,\n",
      "          -3.8439, -0.5201],\n",
      "         [ 1.5743, -0.8323,  0.6028,  1.2895,  1.3479,  0.9121,  2.3275,\n",
      "           1.0439,  1.2005, -0.8282, -2.3070,  1.7809,  0.1308,  2.3806,\n",
      "          -0.5963, -0.5704],\n",
      "         [ 0.9648, -0.5366,  0.3519, -0.3219, -3.9342,  0.8958, -0.7739,\n",
      "           1.7005,  2.3809, -0.5410,  0.3183,  0.6615, -0.9699,  1.2518,\n",
      "          -0.6107,  0.4583],\n",
      "         [-0.5368, -0.5864, -1.7717, -0.8224,  2.7603, -2.0044,  1.9278,\n",
      "           0.9824, -1.0042,  0.2768,  0.6562,  0.9508, -1.7235,  0.7636,\n",
      "           3.2829,  0.0728],\n",
      "         [ 0.9169, -1.9761, -1.9478,  1.6504, -1.0098, -0.3263,  1.1207,\n",
      "          -1.1906, -1.9616, -0.1290,  0.8681, -2.2043, -0.0309,  0.2950,\n",
      "          -0.1788,  2.1187],\n",
      "         [ 0.3680, -0.6565, -0.3603, -1.3817, -2.6843,  1.9339, -1.5515,\n",
      "           0.4167,  3.0031,  0.5071,  1.0425, -3.5753,  1.3488,  1.7356,\n",
      "           0.0533,  1.9878],\n",
      "         [ 1.6746, -0.2766, -0.9755, -0.3644, -0.9928,  0.6322,  0.7435,\n",
      "          -1.3328,  1.8017, -3.2040, -0.2429, -0.6646, -2.1029, -0.1100,\n",
      "           0.2537, -1.0512],\n",
      "         [-0.2972, -0.7381,  4.0814,  1.1156,  1.7704, -1.3947, -1.1105,\n",
      "           0.0087, -1.0974, -0.1742,  0.6234, -0.2097,  0.3459,  0.0169,\n",
      "          -0.9470,  0.5765],\n",
      "         [ 0.4504,  1.3929,  0.1681, -3.2117,  0.1277,  0.0719,  0.0538,\n",
      "          -0.4980, -0.0174,  1.2379, -1.2558, -0.4557, -0.3192, -1.7378,\n",
      "           2.0956, -1.3731]],\n",
      "\n",
      "        [[ 0.5976, -0.7189,  2.8166, -0.1321,  1.0052,  1.0234,  1.2974,\n",
      "          -1.3262,  0.5621,  1.6201, -0.2827, -0.7895,  1.3373,  3.3113,\n",
      "          -1.3641,  0.0736],\n",
      "         [ 0.7235,  0.6014, -1.3282, -0.4339,  4.0799,  2.8853, -0.9940,\n",
      "           1.3620,  1.3924,  0.2733, -0.0780,  1.6752,  1.1182, -0.2730,\n",
      "          -4.2420, -0.0582],\n",
      "         [ 2.6725, -1.0379,  0.6328,  0.0963,  0.1257,  2.6072,  1.9678,\n",
      "          -0.5548,  1.6901,  0.1581, -1.8239,  3.0970,  1.8218,  0.8353,\n",
      "          -0.3555, -1.2327],\n",
      "         [ 0.2269, -0.7618,  0.9876, -0.0622, -0.7635,  1.0380,  0.1255,\n",
      "           2.2092,  0.4528, -1.0042, -0.3265,  0.6080, -1.1384, -0.8603,\n",
      "          -0.9188, -0.2095],\n",
      "         [-0.9673, -1.1145,  0.0587, -0.7745,  0.7458,  1.5968, -0.4407,\n",
      "           0.1108,  0.5718, -0.5434,  0.2305, -0.3260, -0.8161,  0.5103,\n",
      "           0.6672, -2.1222],\n",
      "         [ 0.7150,  0.2594, -1.3623,  3.3103,  0.0047, -2.0766,  1.5654,\n",
      "          -0.9383, -0.5336, -1.2893,  1.7075, -1.0803, -0.3973, -1.4976,\n",
      "           0.4262,  2.4084],\n",
      "         [ 1.0049,  0.9587,  1.7029, -0.9554,  0.4606,  0.4357,  1.5019,\n",
      "          -1.0617,  1.0877,  1.3384, -0.1831, -2.7199,  1.0762,  2.1336,\n",
      "          -1.7673,  0.0782],\n",
      "         [ 1.7169,  0.1664,  0.9883, -0.4820, -3.0774,  0.5444, -0.1437,\n",
      "           0.4824,  0.4449, -0.6428, -0.4411,  1.0445, -2.0496,  1.1019,\n",
      "           2.9239,  0.1333],\n",
      "         [-1.2147, -2.7185,  1.3979, -0.1572,  0.2735,  0.8654, -0.2081,\n",
      "          -0.6607,  1.2366, -0.9220,  1.1632, -0.1920,  2.2014, -1.8898,\n",
      "          -0.8699,  1.4229],\n",
      "         [-0.4136,  0.3487,  1.7752, -2.1188,  0.0739,  1.0819,  0.4057,\n",
      "           1.5958,  2.0492,  1.4814, -0.5512, -1.9858, -2.2092, -0.4479,\n",
      "           0.4042, -2.4923]]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class LearnablePositionalEncoding(nn.Module):\n",
    "    def __init__(self, seq_length, d_model):\n",
    "        super(LearnablePositionalEncoding, self).__init__()\n",
    "        # Learnable positional encoding (initialized randomly)\n",
    "        self.positional_encoding = nn.Parameter(torch.randn(1, seq_length, d_model))\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Adds positional encoding to the input tensor.\n",
    "\n",
    "        Args:\n",
    "            x: Input tensor of shape (batch_size, seq_length, d_model)\n",
    "\n",
    "        Returns:\n",
    "            A tensor with positional encoding added to the input\n",
    "        \"\"\"\n",
    "        return x + self.positional_encoding\n",
    "\n",
    "# Example usage\n",
    "seq_length = 10 # max 10 words in each sentence\n",
    "d_model = 16 # each word is vectorized into 1 x 16 array\n",
    "batch_size = 2 # two sentences\n",
    "\n",
    "# Sample input tensor (random values)\n",
    "x = torch.randn(batch_size, seq_length, d_model)\n",
    "\n",
    "# Create the learnable positional encoding layer\n",
    "pos_encoding_layer = LearnablePositionalEncoding(seq_length, d_model)\n",
    "\n",
    "# Forward pass\n",
    "output = pos_encoding_layer(x)\n",
    "\n",
    "print(\"Learnable Positional Encoding:\\n\", pos_encoding_layer.positional_encoding)\n",
    "print(\"Input + Positional Encoding:\\n\", output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8d7d47",
   "metadata": {},
   "source": [
    "**Explanation:**\n",
    "- Learnable Positional Encoding: Instead of calculating the positional encoding using sine and cosine functions, the encoding is now a trainable tensor, initialized randomly, and learned during model training.\n",
    "- Positional Encoding Parameter: self.positional_encoding is an nn.Parameter that holds the learnable positional encodings for the sequence. The shape is (1, seq_length, d_model) so that the same positional encodings are applied across different batches.\n",
    "- Forward Pass: The input tensor x (with shape (batch_size, seq_length, d_model)) is summed with the positional encoding, adding positional information to the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749a36de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
