{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0a0e0c7",
   "metadata": {},
   "source": [
    "# RNN Example 2: Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5dc2718c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3d40e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def param_toWeights(param):    \n",
    "    #parameter U: x(t) -> h(t), 3 x 2\n",
    "    input_weights_U = np.array([[param[0], param[1]],\n",
    "                                [param[2], param[3]],\n",
    "                                [param[4],param[5]]]) \n",
    "    #parameter W: x(t) -> h(t), 3 x 3\n",
    "    hidden_weights_W =  np.array([[param[6], param[7], param[8]],\n",
    "                                  [param[9], param[10], param[11]],\n",
    "                                  [param[12], param[13], param[14]]]) \n",
    "    #parameter b: a(t)=b+W h(t-1)+Ux(t) and h(t) = tahn(a(t)), 3 x 1\n",
    "    hidden_bias = np.array([[param[15]],\n",
    "                            [param[16]],\n",
    "                            [param[17]]]) \n",
    "    #parameter V: y(t)= c + Vh(t) 2 x 3\n",
    "    output_weights_V = np.array([[param[18], param[19], param[20]],\n",
    "                                 [param[21], param[22], param[23]]])\n",
    "    #parameter c: y(t)= c + Vh(t) 2 x 1\n",
    "    output_bias =  np.array([[param[24]],\n",
    "                             [param[25]]]) \n",
    "\n",
    "    return input_weights_U, hidden_weights_W, hidden_bias, output_weights_V, output_bias\n",
    "\n",
    "def RNN_CrossEntropy(param,*args):\n",
    "    #Initialize weights and biases\n",
    "    input_weights_U, hidden_weights_W, hidden_bias, output_weights_V, output_bias = param_toWeights(param)\n",
    "    #Check what happens when we run the network using these weights?\n",
    "    #Forward pass\n",
    "    xs, target, hidden_states, outputs, probabilities = {}, {}, {}, {}, {}\n",
    "    # cumsum of log density --> likelihood\n",
    "    loss = 0 \n",
    "    hidden_states[-1] = np.copy(hidden_state_prev)\n",
    "    for t in range(len(inputs)): \n",
    "        # one-hot-encoding the input character \n",
    "        xs[t] = np.zeros((vocab_size,1))  \n",
    "        character = inputs[t]\n",
    "        xs[t][character] = 1 \n",
    "        target[t] = np.zeros((vocab_size,1))  # 2 x 1\n",
    "        target_character = targets[t]\n",
    "        target[t][target_character] = 1\n",
    "        # Compute hidden state \n",
    "        hidden_states[t] = np.tanh(input_weights_U @ xs[t] + hidden_weights_W @ hidden_states[t-1] + hidden_bias) \n",
    "        # Compute output and probabilities\n",
    "        outputs[t] = output_weights_V @ hidden_states[t] + output_bias\n",
    "        probabilities[t] = np.exp(outputs[t]) / np.sum(np.exp(outputs[t]))\n",
    "        #Compute cross-entropy loss\n",
    "        loss += - sum(target[t] * np.log(probabilities[t]))\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aff1cf85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000000\n",
      "         Iterations: 20\n",
      "         Function evaluations: 702\n",
      "         Gradient evaluations: 26\n",
      "The optimal input weights U are:\n",
      "[[ 0.84182004 -0.85639161]\n",
      " [-3.11145965  3.10381649]\n",
      " [-5.73631536  5.71312205]]\n",
      "The optimal hidden state weights W are:\n",
      "[[-0.26263566  0.33832677 -0.19223223]\n",
      " [ 1.30427041 -1.44103652  1.22418215]\n",
      " [ 2.67612822 -2.89916107  2.65021927]]\n",
      "The optimal hidden state bias b are:\n",
      "[[-0.03528076]\n",
      " [-0.02285487]\n",
      " [-0.02064066]]\n",
      "The optimal output weights V are:\n",
      "[[-0.34853607  2.96739134  7.02440513]\n",
      " [ 0.33641209 -2.94872708 -7.02584119]]\n",
      "The optimal output bias c are:\n",
      "[[-0.03097484]\n",
      " [ 0.03098114]]\n"
     ]
    }
   ],
   "source": [
    "# ============================ # \n",
    "# RNN STARTS:\n",
    "# ============================ #  \n",
    "#Initialize inputs and targets\n",
    "vocab_size = 2\n",
    "hidden_size = 3\n",
    "hidden_state_prev =  np.array([[0.95],[-0.98],[0.98]]) \n",
    "inputs = [1,0,1,0]\n",
    "targets = [0,1,0,1]\n",
    "\n",
    "#Initialize weights and biases (parameters)\n",
    "#parameter U: x(t) -> h(t), 3 x 2\n",
    "input_weights_U = np.random.randn(hidden_size, vocab_size) * 0.01\n",
    "input_weights_U_stack = np.hstack(input_weights_U)\n",
    "#parameter W: x(t) -> h(t), 3 x 3\n",
    "hidden_weights_W = np.random.randn(hidden_size, hidden_size) * 0.01\n",
    "hidden_weights_W_stack = np.hstack(hidden_weights_W)\n",
    "#parameter b: a(t)=b+W h(t-1)+Ux(t) and h(t) = tahn(a(t)), 3 x 1\n",
    "hidden_bias = np.zeros((hidden_size, 1)) \n",
    "hidden_bias_stack = np.hstack(hidden_bias)\n",
    "#parameter V: y(t)= c + Vh(t) 2 x 3\n",
    "output_weights_V = np.random.randn(vocab_size, hidden_size) * 0.01\n",
    "output_weights_V_stack = np.hstack(output_weights_V)\n",
    "#parameter c: y(t)= c + Vh(t) 2 x 1\n",
    "output_bias = np.zeros((vocab_size, 1))\n",
    "output_bias_stack = np.hstack(output_bias)\n",
    "\n",
    "param0 = np.hstack((input_weights_U_stack,hidden_weights_W_stack,hidden_bias_stack,\n",
    "                   output_weights_V_stack, output_bias_stack))\n",
    "results = minimize(RNN_CrossEntropy, param0, method='BFGS', tol=1e-8, options={'disp': True})\n",
    "param_star = results.x\n",
    "\n",
    "# ============================ #\n",
    "# PARAMETER ESTIMATES: \n",
    "# ============================ #    \n",
    "input_weights_U_star, \\\n",
    "hidden_weights_W_star, \\\n",
    "hidden_bias_star, \\\n",
    "output_weights_V_star, \\\n",
    "output_bias_star = param_toWeights(param_star)\n",
    "\n",
    "print('The optimal input weights U are:')\n",
    "print(input_weights_U_star)\n",
    "print('The optimal hidden state weights W are:')\n",
    "print(hidden_weights_W_star)\n",
    "print('The optimal hidden state bias b are:')\n",
    "print(hidden_bias_star)\n",
    "print('The optimal output weights V are:')\n",
    "print(output_weights_V_star)\n",
    "print('The optimal output bias c are:')\n",
    "print(output_bias_star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c5cff0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
